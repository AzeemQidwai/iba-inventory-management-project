{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 455, 'depth': 5, 'learning_rate': 0.014084457904985567, 'subsample': 0.70839194529896}\n",
      "Best Model RMSE: 214.87467987253933\n",
      "Hyperparameter tuning and logging to specified experiment complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import optuna\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load your data (use your actual file path)\n",
    "file_path = '../data/combined_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Renaming the columns as per the user's mapping\n",
    "data.rename(columns={\n",
    "    'Material': 'Material Code',\n",
    "    'Material Description': 'Material Description',\n",
    "    'Opening Stock': 'Open Stock',\n",
    "    'Total Issue Quantities': 'Material Issued',\n",
    "    'Total Receipt Qties': 'Material Received',\n",
    "    'Closing Stock': 'Closing Stock',\n",
    "    'From Date': 'Date',\n",
    "    'BUn': 'Unit'\n",
    "}, inplace=True)\n",
    "\n",
    "# Preprocessing\n",
    "data['Date'] = pd.to_datetime(data['Date'], format=\"%d.%m.%Y\")\n",
    "data.sort_values('Date', inplace=True)\n",
    "data = data.dropna(subset=['Material Issued', 'Open Stock', 'Closing Stock'])\n",
    "data['Material Issued'] = data['Material Issued'].abs()\n",
    "data['Material Code'] = data['Material Code'].astype(str)\n",
    "\n",
    "# Feature Engineering\n",
    "data['Day'] = data['Date'].dt.day\n",
    "data['Month'] = data['Date'].dt.month\n",
    "data['Year'] = data['Date'].dt.year\n",
    "\n",
    "# Add 1-day Lag Feature\n",
    "data['Lag_1_Issued'] = data.groupby('Material Code')['Material Issued'].shift(1)\n",
    "\n",
    "# Add 7-day Rolling Statistics\n",
    "data['Rolling_7_Issued'] = data.groupby('Material Code')['Material Issued'].rolling(7).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "# Add Seasonality Indicator (e.g., Weekday)\n",
    "data['Weekday'] = data['Date'].dt.weekday  # 0=Monday, 6=Sunday\n",
    "\n",
    "# Fill NaN values introduced by lagging and rolling\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "# Target and Features\n",
    "features = ['Open Stock', 'Closing Stock', 'Day', 'Month', 'Year', 'Material Code', 'Lag_1_Issued', 'Rolling_7_Issued', 'Weekday']\n",
    "X = data[features]\n",
    "y = data['Material Issued']\n",
    "\n",
    "# Set up MLflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "\n",
    "# Create MLflow experiment\n",
    "experiment_name = \"Hyperparameter Tuning with Optuna (CatBoost)\"\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(name=experiment_name)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 500)\n",
    "    depth = trial.suggest_int(\"depth\", 3, 15)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.3)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.6, 1.0)\n",
    "\n",
    "    # Define model\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=n_estimators,\n",
    "        depth=depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        cat_features=['Material Code'],\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Time-based cross-validation\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    rmse_scores = []\n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        model.fit(X_train, y_train, cat_features=['Material Code'])\n",
    "        preds = model.predict(X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "        rmse_scores.append(rmse)\n",
    "\n",
    "    mean_rmse = np.mean(rmse_scores)\n",
    "\n",
    "    # Log parameters and metrics to MLflow\n",
    "    with mlflow.start_run(experiment_id=experiment_id, nested=True):\n",
    "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "        mlflow.log_param(\"depth\", depth)\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "        mlflow.log_param(\"subsample\", subsample)\n",
    "        mlflow.log_metric(\"rmse\", mean_rmse)\n",
    "\n",
    "    return mean_rmse\n",
    "\n",
    "# Suppress experimental warnings\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(study_name=experiment_name, direction=\"minimize\", storage=\"sqlite:///optuna.db\", load_if_exists=True)\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Best trial results\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Train and evaluate the best model\n",
    "best_model = CatBoostRegressor(\n",
    "    iterations=best_params[\"n_estimators\"],\n",
    "    depth=best_params[\"depth\"],\n",
    "    learning_rate=best_params[\"learning_rate\"],\n",
    "    subsample=best_params[\"subsample\"],\n",
    "    cat_features=['Material Code'],\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Time-based split\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "best_model.fit(X_train, y_train, cat_features=['Material Code'])\n",
    "predictions = best_model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"Best Model RMSE: {rmse}\")\n",
    "\n",
    "# Save the model as a .pkl file\n",
    "model_path = \"best_catboost_model.pkl\"\n",
    "joblib.dump(best_model, model_path)\n",
    "\n",
    "# Log the best model to MLflow\n",
    "with mlflow.start_run(experiment_id=experiment_id):\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metric(\"final_rmse\", rmse)\n",
    "    mlflow.log_artifact(model_path, artifact_path=\"models\")\n",
    "\n",
    "print(\"Hyperparameter tuning and logging to specified experiment complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters saved to best_params.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Save best_params to a JSON file\n",
    "with open('best_params_catboost.json', 'w') as json_file:\n",
    "    json.dump(best_params, json_file)\n",
    "\n",
    "print(\"Best parameters saved to best_params.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'iterations': 180, 'depth': 5, 'learning_rate': 0.07082428899762874, 'subsample': 0.9650214403608193, 'colsample_bylevel': 0.6490829813452552}\n",
      "Best Model RMSE: 224.98576815377612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IBA-Project\\iba-inventory-management-project\\project_env\\Lib\\site-packages\\mlflow\\types\\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea97b94de164f0dade20c42dae416fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter tuning and logging to specified experiment complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import optuna\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load your data (use your actual file path)\n",
    "file_path = '../data/inventory.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data = data[data['Type'] == 'Material']\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data['Material Code'] = data['Material Code'].astype(str)\n",
    "\n",
    "data.sort_values('Date', inplace=True)\n",
    "data = data.dropna(subset=['Material Issued', 'Open Stock', 'Closing Stock'])\n",
    "\n",
    "# Feature Engineering\n",
    "data['Day'] = data['Date'].dt.day\n",
    "data['Month'] = data['Date'].dt.month\n",
    "data['Year'] = data['Date'].dt.year\n",
    "\n",
    "# Add 1-day Lag Feature\n",
    "data['Lag_1_Issued'] = data.groupby('Material Code')['Material Issued'].shift(1)\n",
    "\n",
    "# Add 7-day Rolling Statistics\n",
    "data['Rolling_7_Issued'] = data.groupby('Material Code')['Material Issued'].rolling(7).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "# Add Seasonality Indicator (e.g., Weekday)\n",
    "data['Weekday'] = data['Date'].dt.weekday  # 0=Monday, 6=Sunday\n",
    "\n",
    "# Fill NaN values introduced by lagging and rolling\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "# Target and Features\n",
    "features = ['Open Stock', 'Closing Stock', 'Day', 'Month', 'Year', 'Material Code', 'Lag_1_Issued', 'Rolling_7_Issued', 'Weekday', 'BFP']\n",
    "X = data[features]\n",
    "y = data['Material Issued']\n",
    "\n",
    "# Set up MLflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "\n",
    "# Create MLflow experiment\n",
    "experiment_name = \"Hyperparameter Tuning with Optuna (CatBoost - Material)\"\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(name=experiment_name)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    iterations = trial.suggest_int(\"iterations\", 50, 500)\n",
    "    depth = trial.suggest_int(\"depth\", 3, 15)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.3)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.6, 1.0)\n",
    "    colsample_bylevel = trial.suggest_float(\"colsample_bylevel\", 0.6, 1.0)\n",
    "\n",
    "    # Define model\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=iterations,\n",
    "        depth=depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bylevel=colsample_bylevel,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Time-based cross-validation\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    rmse_scores = []\n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        train_pool = Pool(X_train, y_train, cat_features=['Material Code'])\n",
    "        test_pool = Pool(X_test, y_test, cat_features=['Material Code'])\n",
    "        model.fit(train_pool)\n",
    "        preds = model.predict(test_pool)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "        rmse_scores.append(rmse)\n",
    "\n",
    "    mean_rmse = np.mean(rmse_scores)\n",
    "\n",
    "    # Log parameters and metrics to MLflow\n",
    "    with mlflow.start_run(experiment_id=experiment_id, nested=True):\n",
    "        mlflow.log_param(\"iterations\", iterations)\n",
    "        mlflow.log_param(\"depth\", depth)\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "        mlflow.log_param(\"subsample\", subsample)\n",
    "        mlflow.log_param(\"colsample_bylevel\", colsample_bylevel)\n",
    "        mlflow.log_metric(\"rmse\", mean_rmse)\n",
    "\n",
    "    return mean_rmse\n",
    "\n",
    "# Suppress experimental warnings\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(study_name=experiment_name, direction=\"minimize\", storage=\"sqlite:///optuna.db\", load_if_exists=True)\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Best trial results\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Train and evaluate the best model\n",
    "best_model = CatBoostRegressor(\n",
    "    iterations=best_params[\"iterations\"],\n",
    "    depth=best_params[\"depth\"],\n",
    "    learning_rate=best_params[\"learning_rate\"],\n",
    "    subsample=best_params[\"subsample\"],\n",
    "    colsample_bylevel=best_params[\"colsample_bylevel\"],\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Time-based split\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "train_pool = Pool(X_train, y_train, cat_features=['Material Code'])\n",
    "test_pool = Pool(X_test, y_test, cat_features=['Material Code'])\n",
    "\n",
    "best_model.fit(train_pool)\n",
    "predictions = best_model.predict(test_pool)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"Best Model RMSE: {rmse}\")\n",
    "\n",
    "# Save the model as a .pkl file\n",
    "model_path = \"best_catboost_model_material.pkl\"\n",
    "joblib.dump(best_model, model_path)\n",
    "\n",
    "# Log the best model to MLflow\n",
    "with mlflow.start_run(experiment_id=experiment_id):\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metric(\"final_rmse\", rmse)\n",
    "    mlflow.catboost.log_model(best_model, \"model\", input_example=X_train.iloc[:5])\n",
    "\n",
    "print(\"Hyperparameter tuning and logging to specified experiment complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save best_params to a JSON file\n",
    "with open('best_params_catboost_material.json', 'w') as json_file:\n",
    "    json.dump(best_params, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'iterations': 418, 'depth': 6, 'learning_rate': 0.21849155230550643, 'subsample': 0.8535524515709212, 'colsample_bylevel': 0.9583336280226162}\n",
      "Best Model RMSE: 95.27078769392703\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "`python_model` must be a PythonModel instance, callable object, or path to a script that uses set_model() to set a PythonModel instance or callable object.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 160\u001b[0m\n\u001b[0;32m    158\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_params(best_params)\n\u001b[0;32m    159\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_rmse\u001b[39m\u001b[38;5;124m\"\u001b[39m, rmse)\n\u001b[1;32m--> 160\u001b[0m     \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpython_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcatboost_env\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchannels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdefaults\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdependencies\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpython=3.8.10\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmlflow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcatboost==1.0.6\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpandas\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnumpy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscikit-learn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m    173\u001b[0m \u001b[43m                \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Provide a sample of the input data\u001b[39;49;00m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperparameter tuning and logging to specified experiment complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\IBA-Project\\iba-inventory-management-project\\project_env\\Lib\\site-packages\\mlflow\\tracing\\provider.py:309\u001b[0m, in \u001b[0;36mtrace_disabled.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    307\u001b[0m disable()\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 309\u001b[0m     is_func_called, result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    311\u001b[0m     enable()\n",
      "File \u001b[1;32md:\\IBA-Project\\iba-inventory-management-project\\project_env\\Lib\\site-packages\\mlflow\\pyfunc\\__init__.py:3263\u001b[0m, in \u001b[0;36mlog_model\u001b[1;34m(artifact_path, loader_module, data_path, code_path, code_paths, infer_code_paths, conda_env, python_model, artifacts, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, metadata, model_config, example_no_conversion, streamable, resources)\u001b[0m\n\u001b[0;32m   3041\u001b[0m \u001b[38;5;129m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS\u001b[38;5;241m.\u001b[39mformat(package_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscikit-learn\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   3042\u001b[0m \u001b[38;5;129m@trace_disabled\u001b[39m  \u001b[38;5;66;03m# Suppress traces for internal predict calls while logging model\u001b[39;00m\n\u001b[0;32m   3043\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_model\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     resources: Optional[Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[Resource]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3064\u001b[0m ):\n\u001b[0;32m   3065\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3066\u001b[0m \u001b[38;5;124;03m    Log a Pyfunc model with custom inference logic and optional data dependencies as an MLflow\u001b[39;00m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;124;03m    artifact for the current run.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3261\u001b[0m \u001b[38;5;124;03m        metadata of the logged model.\u001b[39;00m\n\u001b[0;32m   3262\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3264\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# deprecated\u001b[39;49;00m\n\u001b[0;32m   3269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpython_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpython_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3271\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifacts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifacts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3274\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3275\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_no_conversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample_no_conversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3284\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer_code_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_code_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3285\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\IBA-Project\\iba-inventory-management-project\\project_env\\Lib\\site-packages\\mlflow\\models\\model.py:776\u001b[0m, in \u001b[0;36mModel.log\u001b[1;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, **kwargs)\u001b[0m\n\u001b[0;32m    772\u001b[0m     run_id \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mtracking\u001b[38;5;241m.\u001b[39mfluent\u001b[38;5;241m.\u001b[39m_get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[0;32m    773\u001b[0m mlflow_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    774\u001b[0m     artifact_path\u001b[38;5;241m=\u001b[39martifact_path, run_id\u001b[38;5;241m=\u001b[39mrun_id, metadata\u001b[38;5;241m=\u001b[39mmetadata, resources\u001b[38;5;241m=\u001b[39mresources\n\u001b[0;32m    775\u001b[0m )\n\u001b[1;32m--> 776\u001b[0m \u001b[43mflavor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;66;03m# `save_model` calls `load_model` to infer the model requirements, which may result in\u001b[39;00m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;66;03m# __pycache__ directories being created in the model directory.\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pycache \u001b[38;5;129;01min\u001b[39;00m Path(local_path)\u001b[38;5;241m.\u001b[39mrglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__pycache__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32md:\\IBA-Project\\iba-inventory-management-project\\project_env\\Lib\\site-packages\\mlflow\\tracing\\provider.py:313\u001b[0m, in \u001b[0;36mtrace_disabled.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m             enable()\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 313\u001b[0m         is_func_called, result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;66;03m# We should only catch the exception from disable() and enable()\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;66;03m# and let other exceptions propagate.\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MlflowTracingException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\IBA-Project\\iba-inventory-management-project\\project_env\\Lib\\site-packages\\mlflow\\pyfunc\\__init__.py:2836\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(path, loader_module, data_path, code_path, code_paths, infer_code_paths, conda_env, mlflow_model, python_model, artifacts, signature, input_example, pip_requirements, extra_pip_requirements, metadata, model_config, example_no_conversion, streamable, resources, **kwargs)\u001b[0m\n\u001b[0;32m   2833\u001b[0m     _validate_and_copy_file_to_directory(model_code_path, path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2834\u001b[0m     python_model \u001b[38;5;241m=\u001b[39m _load_model_code_path(model_code_path, model_config)\n\u001b[1;32m-> 2836\u001b[0m \u001b[43m_validate_function_python_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpython_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(python_model) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m   2838\u001b[0m     a \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m (input_example, pip_requirements, extra_pip_requirements)\n\u001b[0;32m   2839\u001b[0m ):\n\u001b[0;32m   2840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m   2841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf `python_model` is a callable object, at least one of `input_example`, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip_requirements`, or `extra_pip_requirements` must be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2843\u001b[0m     )\n",
      "File \u001b[1;32md:\\IBA-Project\\iba-inventory-management-project\\project_env\\Lib\\site-packages\\mlflow\\pyfunc\\__init__.py:2597\u001b[0m, in \u001b[0;36m_validate_function_python_model\u001b[1;34m(python_model)\u001b[0m\n\u001b[0;32m   2595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_function_python_model\u001b[39m(python_model):\n\u001b[0;32m   2596\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(python_model, PythonModel) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(python_model)):\n\u001b[1;32m-> 2597\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m   2598\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`python_model` must be a PythonModel instance, callable object, or path to a script \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2599\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat uses set_model() to set a PythonModel instance or callable object.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2600\u001b[0m             error_code\u001b[38;5;241m=\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[0;32m   2601\u001b[0m         )\n\u001b[0;32m   2603\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(python_model):\n\u001b[0;32m   2604\u001b[0m         num_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(inspect\u001b[38;5;241m.\u001b[39msignature(python_model)\u001b[38;5;241m.\u001b[39mparameters)\n",
      "\u001b[1;31mMlflowException\u001b[0m: `python_model` must be a PythonModel instance, callable object, or path to a script that uses set_model() to set a PythonModel instance or callable object."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import optuna\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load your data (use your actual file path)\n",
    "file_path = '../data/inventory.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data = data[data['Type'] == 'Material']\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data['Material Code'] = data['Material Code'].astype(str)\n",
    "\n",
    "data.sort_values('Date', inplace=True)\n",
    "data = data.dropna(subset=['Material Issued', 'Open Stock', 'Closing Stock', 'Price'])\n",
    "\n",
    "# Calculate Amount Issued and Amount Received\n",
    "data['Amount Issued'] = data['Price'] * data['Material Issued']\n",
    "data['Amount Received'] = data['Price'] * data['Material Received']\n",
    "\n",
    "# Feature Engineering\n",
    "data['Day'] = data['Date'].dt.day\n",
    "data['Month'] = data['Date'].dt.month\n",
    "data['Year'] = data['Date'].dt.year\n",
    "data['Quarter'] = data['Date'].dt.quarter\n",
    "\n",
    "# Add 1-day Lag Feature\n",
    "data['Lag_1_Issued'] = data.groupby('Material Code')['Material Issued'].shift(1)\n",
    "data['Lag_1_Amount_Issued'] = data.groupby('Material Code')['Amount Issued'].shift(1)\n",
    "\n",
    "# Add 7-day Rolling Statistics\n",
    "data['Rolling_7_Issued'] = data.groupby('Material Code')['Material Issued'].rolling(7).mean().reset_index(level=0, drop=True)\n",
    "data['Rolling_7_Amount_Issued'] = data.groupby('Material Code')['Amount Issued'].rolling(7).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "# Add Seasonality Indicator (e.g., Weekday)\n",
    "data['Weekday'] = data['Date'].dt.weekday  # 0=Monday, 6=Sunday\n",
    "\n",
    "# Cumulative Features\n",
    "data['Cumulative_Issued'] = data.groupby('Material Code')['Material Issued'].cumsum()\n",
    "data['Cumulative_Received'] = data.groupby('Material Code')['Material Received'].cumsum()\n",
    "data['Cumulative_Amount_Issued'] = data.groupby('Material Code')['Amount Issued'].cumsum()\n",
    "\n",
    "# Interaction Features\n",
    "data['Price_Issued_Interaction'] = data['Price'] * data['Material Issued']\n",
    "\n",
    "# Fill NaN values introduced by lagging and rolling\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "# Target and Features\n",
    "features = ['Open Stock', 'Closing Stock', 'Day', 'Year', 'Material Code', 'Lag_1_Issued', 'Rolling_7_Issued', 'Weekday', 'BFP', 'Lag_1_Amount_Issued', 'Rolling_7_Amount_Issued', 'Cumulative_Issued', 'Cumulative_Received', 'Cumulative_Amount_Issued', 'Price_Issued_Interaction']\n",
    "X = data[features]\n",
    "y = data['Material Issued']\n",
    "\n",
    "# Set up MLflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "\n",
    "# Create MLflow experiment\n",
    "experiment_name = \"Hyperparameter Tuning with Optuna (CatBoost - Material - Added Features)\"\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(name=experiment_name)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    iterations = trial.suggest_int(\"iterations\", 50, 500)\n",
    "    depth = trial.suggest_int(\"depth\", 3, 15)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.3)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.6, 1.0)\n",
    "    colsample_bylevel = trial.suggest_float(\"colsample_bylevel\", 0.6, 1.0)\n",
    "\n",
    "    # Define model\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=iterations,\n",
    "        depth=depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bylevel=colsample_bylevel,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Time-based cross-validation\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    rmse_scores = []\n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        train_pool = Pool(X_train, y_train, cat_features=['Material Code'])\n",
    "        test_pool = Pool(X_test, y_test, cat_features=['Material Code'])\n",
    "        model.fit(train_pool)\n",
    "        preds = model.predict(test_pool)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "        rmse_scores.append(rmse)\n",
    "\n",
    "    mean_rmse = np.mean(rmse_scores)\n",
    "\n",
    "    # Log parameters and metrics to MLflow\n",
    "    with mlflow.start_run(experiment_id=experiment_id, nested=True):\n",
    "        mlflow.log_param(\"iterations\", iterations)\n",
    "        mlflow.log_param(\"depth\", depth)\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "        mlflow.log_param(\"subsample\", subsample)\n",
    "        mlflow.log_param(\"colsample_bylevel\", colsample_bylevel)\n",
    "        mlflow.log_metric(\"rmse\", mean_rmse)\n",
    "\n",
    "    return mean_rmse\n",
    "\n",
    "# Suppress experimental warnings\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(study_name=experiment_name, direction=\"minimize\", storage=\"sqlite:///optuna.db\", load_if_exists=True)\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Best trial results\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Train and evaluate the best model\n",
    "best_model = CatBoostRegressor(\n",
    "    iterations=best_params[\"iterations\"],\n",
    "    depth=best_params[\"depth\"],\n",
    "    learning_rate=best_params[\"learning_rate\"],\n",
    "    subsample=best_params[\"subsample\"],\n",
    "    colsample_bylevel=best_params[\"colsample_bylevel\"],\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Time-based split\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "train_pool = Pool(X_train, y_train, cat_features=['Material Code'])\n",
    "test_pool = Pool(X_test, y_test, cat_features=['Material Code'])\n",
    "\n",
    "best_model.fit(train_pool)\n",
    "predictions = best_model.predict(test_pool)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"Best Model RMSE: {rmse}\")\n",
    "\n",
    "# Save the model as a .pkl file\n",
    "model_path = \"best_catboost_model_material_features_added.pkl\"\n",
    "joblib.dump(best_model, model_path)\n",
    "\n",
    "# Log the best model to MLflow with dependencies and input example\n",
    "with mlflow.start_run(experiment_id=experiment_id):\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metric(\"final_rmse\", rmse)\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",\n",
    "        python_model=best_model,\n",
    "        conda_env={\n",
    "            'name': 'catboost_env',\n",
    "            'channels': ['defaults'],\n",
    "            'dependencies': ['python=3.8.10', 'pip', {\n",
    "                'pip': [\n",
    "                    'mlflow',\n",
    "                    'catboost==1.0.6',\n",
    "                    'pandas',\n",
    "                    'numpy',\n",
    "                    'scikit-learn'\n",
    "                ]\n",
    "            }]\n",
    "        },\n",
    "        input_example=X_train.iloc[:5]  # Provide a sample of the input data\n",
    "    )\n",
    "\n",
    "print(\"Hyperparameter tuning and logging to specified experiment complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save best_params to a JSON file\n",
    "with open('best_params_catboost_material_features_added.json', 'w') as json_file:\n",
    "    json.dump(best_params, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-14 19:42:49,421] Trial 26 failed with parameters: {'iterations': 445, 'depth': 12, 'learning_rate': 0.04763191825317156, 'subsample': 0.6726097446898451, 'colsample_bylevel': 0.9514938333249534} because of the following error: KeyboardInterrupt('').\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\IBA-Project\\iba-inventory-management-project\\project_env\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\azeem\\AppData\\Local\\Temp\\ipykernel_33924\\3093344631.py\", line 99, in objective\n",
      "    model.fit(train_pool)\n",
      "  File \"d:\\IBA-Project\\iba-inventory-management-project\\project_env\\Lib\\site-packages\\catboost\\core.py\", line 5873, in fit\n",
      "    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\IBA-Project\\iba-inventory-management-project\\project_env\\Lib\\site-packages\\catboost\\core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"d:\\IBA-Project\\iba-inventory-management-project\\project_env\\Lib\\site-packages\\catboost\\core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5017, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5066, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n",
      "[W 2025-01-14 19:42:49,425] Trial 26 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 122\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# Run Optuna optimization\u001b[39;00m\n\u001b[0;32m    121\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(study_name\u001b[38;5;241m=\u001b[39mexperiment_name, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m, storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///optuna.db\u001b[39m\u001b[38;5;124m\"\u001b[39m, load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 122\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Best trial results\u001b[39;00m\n\u001b[0;32m    125\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "File \u001b[1;32md:\\IBA-Project\\iba-inventory-management-project\\project_env\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\IBA-Project\\iba-inventory-management-project\\project_env\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32md:\\IBA-Project\\iba-inventory-management-project\\project_env\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32md:\\IBA-Project\\iba-inventory-management-project\\project_env\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32md:\\IBA-Project\\iba-inventory-management-project\\project_env\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[2], line 99\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     97\u001b[0m train_pool \u001b[38;5;241m=\u001b[39m Pool(X_train, y_train, cat_features\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaterial Code\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     98\u001b[0m test_pool \u001b[38;5;241m=\u001b[39m Pool(X_test, y_test, cat_features\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaterial Code\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 99\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_pool)\n\u001b[0;32m    101\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_test, preds))\n",
      "File \u001b[1;32md:\\IBA-Project\\iba-inventory-management-project\\project_env\\Lib\\site-packages\\catboost\\core.py:5873\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m   5872\u001b[0m     CatBoostRegressor\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m-> 5873\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5874\u001b[0m \u001b[43m                 \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5875\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5876\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\IBA-Project\\iba-inventory-management-project\\project_env\\Lib\\site-packages\\catboost\\core.py:2410\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2407\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2409\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2410\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2418\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2419\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32md:\\IBA-Project\\iba-inventory-management-project\\project_env\\Lib\\site-packages\\catboost\\core.py:1790\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1790\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:5017\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:5066\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import optuna\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load your data (use your actual file path)\n",
    "file_path = '../data/monthly_inventory.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data = data[data['Type'] == 'Material']\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data['Material Code'] = data['Material Code'].astype(str)\n",
    "\n",
    "data.sort_values('Date', inplace=True)\n",
    "data = data.dropna(subset=['Material Issued', 'Open Stock', 'Closing Stock', 'Price'])\n",
    "\n",
    "# Calculate Amount Issued and Amount Received\n",
    "data['Amount Issued'] = data['Price'] * data['Material Issued']\n",
    "data['Amount Received'] = data['Price'] * data['Material Received']\n",
    "\n",
    "# Feature Engineering\n",
    "data['Day'] = data['Date'].dt.day\n",
    "data['Month'] = data['Date'].dt.month\n",
    "data['Year'] = data['Date'].dt.year\n",
    "data['Quarter'] = data['Date'].dt.quarter\n",
    "\n",
    "# Add 1-day Lag Feature\n",
    "data['Lag_1_Issued'] = data.groupby('Material Code')['Material Issued'].shift(1)\n",
    "data['Lag_1_Amount_Issued'] = data.groupby('Material Code')['Amount Issued'].shift(1)\n",
    "\n",
    "# Add 7-day Rolling Statistics\n",
    "data['Rolling_7_Issued'] = data.groupby('Material Code')['Material Issued'].rolling(3).mean().reset_index(level=0, drop=True)\n",
    "data['Rolling_7_Amount_Issued'] = data.groupby('Material Code')['Amount Issued'].rolling(3).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "# Add Seasonality Indicator (e.g., Weekday)\n",
    "data['Weekday'] = data['Date'].dt.weekday  # 0=Monday, 6=Sunday\n",
    "\n",
    "# Cumulative Features\n",
    "data['Cumulative_Issued'] = data.groupby('Material Code')['Material Issued'].cumsum()\n",
    "data['Cumulative_Received'] = data.groupby('Material Code')['Material Received'].cumsum()\n",
    "data['Cumulative_Amount_Issued'] = data.groupby('Material Code')['Amount Issued'].cumsum()\n",
    "\n",
    "# Interaction Features\n",
    "data['Price_Issued_Interaction'] = data['Price'] * data['Material Issued']\n",
    "\n",
    "# Fill NaN values introduced by lagging and rolling\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "# Target and Features\n",
    "features = ['Open Stock', 'Closing Stock', 'Day', 'Year', 'Material Code', 'Lag_1_Issued', 'Rolling_7_Issued', 'Weekday', 'BFP', 'Lag_1_Amount_Issued', 'Rolling_7_Amount_Issued', 'Cumulative_Issued', 'Cumulative_Received', 'Cumulative_Amount_Issued', 'Price_Issued_Interaction']\n",
    "X = data[features]\n",
    "y = data['Material Issued']\n",
    "\n",
    "# Set up MLflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "\n",
    "# Create MLflow experiment\n",
    "experiment_name = \"Hyperparameter Tuning with Optuna (CatBoost - Monthly)\"\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(name=experiment_name)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    iterations = trial.suggest_int(\"iterations\", 50, 500)\n",
    "    depth = trial.suggest_int(\"depth\", 3, 15)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.3)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.6, 1.0)\n",
    "    colsample_bylevel = trial.suggest_float(\"colsample_bylevel\", 0.6, 1.0)\n",
    "\n",
    "    # Define model\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=iterations,\n",
    "        depth=depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bylevel=colsample_bylevel,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Time-based cross-validation\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    rmse_scores = []\n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        train_pool = Pool(X_train, y_train, cat_features=['Material Code'])\n",
    "        test_pool = Pool(X_test, y_test, cat_features=['Material Code'])\n",
    "        model.fit(train_pool)\n",
    "        preds = model.predict(test_pool)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "        rmse_scores.append(rmse)\n",
    "\n",
    "    mean_rmse = np.mean(rmse_scores)\n",
    "\n",
    "    # Log parameters and metrics to MLflow\n",
    "    with mlflow.start_run(experiment_id=experiment_id, nested=True):\n",
    "        mlflow.log_param(\"iterations\", iterations)\n",
    "        mlflow.log_param(\"depth\", depth)\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "        mlflow.log_param(\"subsample\", subsample)\n",
    "        mlflow.log_param(\"colsample_bylevel\", colsample_bylevel)\n",
    "        mlflow.log_metric(\"rmse\", mean_rmse)\n",
    "\n",
    "    return mean_rmse\n",
    "\n",
    "# Suppress experimental warnings\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(study_name=experiment_name, direction=\"minimize\", storage=\"sqlite:///optuna.db\", load_if_exists=True)\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Best trial results\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Train and evaluate the best model\n",
    "best_model = CatBoostRegressor(\n",
    "    iterations=best_params[\"iterations\"],\n",
    "    depth=best_params[\"depth\"],\n",
    "    learning_rate=best_params[\"learning_rate\"],\n",
    "    subsample=best_params[\"subsample\"],\n",
    "    colsample_bylevel=best_params[\"colsample_bylevel\"],\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Time-based split\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "train_pool = Pool(X_train, y_train, cat_features=['Material Code'])\n",
    "test_pool = Pool(X_test, y_test, cat_features=['Material Code'])\n",
    "\n",
    "best_model.fit(train_pool)\n",
    "predictions = best_model.predict(test_pool)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"Best Model RMSE: {rmse}\")\n",
    "\n",
    "# Save the model as a .pkl file\n",
    "model_path = \"best_catboost_model_material_features_added.pkl\"\n",
    "joblib.dump(best_model, model_path)\n",
    "\n",
    "# Log the best model to MLflow with dependencies and input example\n",
    "with mlflow.start_run(experiment_id=experiment_id):\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metric(\"final_rmse\", rmse)\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",\n",
    "        python_model=best_model,\n",
    "        conda_env={\n",
    "            'name': 'catboost_env',\n",
    "            'channels': ['defaults'],\n",
    "            'dependencies': ['python=3.8.10', 'pip', {\n",
    "                'pip': [\n",
    "                    'mlflow',\n",
    "                    'catboost==1.0.6',\n",
    "                    'pandas',\n",
    "                    'numpy',\n",
    "                    'scikit-learn'\n",
    "                ]\n",
    "            }]\n",
    "        },\n",
    "        input_example=X_train.iloc[:5]  # Provide a sample of the input data\n",
    "    )\n",
    "\n",
    "print(\"Hyperparameter tuning and logging to specified experiment complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
